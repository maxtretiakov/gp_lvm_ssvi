{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657b44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n",
      "Shapes  A torch.Size([128, 64]) psi1 torch.Size([128, 64]) psi2 torch.Size([128, 128, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtret\\AppData\\Local\\Temp\\ipykernel_45940\\1365297728.py:97: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3679.)\n",
      "  Lam_d = 0.5 * (Lambda_new[d] + Lambda_new[d].T)    # (M, M)\n",
      "  0%|                                                                       | 0/100 [01:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (12) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_45940\\1365297728.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    230\u001b[0m         Lambda_new = ((1.0 - lr) * Lambda_nat\n\u001b[0;32m    231\u001b[0m                       + lr * (Lambda_prior + scale * Q_sum))            # (D, M, M)\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0mset_from_natural\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;31m# ----- monitoring ----------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_45940\\1365297728.py\u001b[0m in \u001b[0;36mset_from_natural\u001b[1;34m(h_new, Lambda_new, eps)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mm_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_u\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mLam_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLambda_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mLambda_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# (M, M)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0meig_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meig_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLam_d\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# (M,), (M, M)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0meig_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meig_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (12) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import math, tarfile, urllib.request, numpy as np, matplotlib.pyplot as plt, torch\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "from sklearn.decomposition import PCA\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# --------------------------- misc -----------------------------------\n",
    "DEV = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEBUG = True                          # print shapes in first outer iter\n",
    "LR_X, LR_HYP = 5e-3, 1e-4\n",
    "BATCH, T_TOTAL, INNER0, INNER = 128, 100, 20, 5\n",
    "JITTER, MAX_EXP, CLIP_QUAD, GR_CLIP = 1e-6, 60.0, 1e6, 10.0\n",
    "BOUNDS = {\"log_sf2\": (-5.0, 6.0), \"log_alpha\": (-5.0, 5.0),\n",
    "          \"log_beta\": (-5.0, 2.0), \"log_s2x\": (-5.0, 5.0)}\n",
    "\n",
    "rho = lambda t, t0=200.0, k=0.7: (t0 + t) ** (-k)          # SVI step size\n",
    "safe_exp = lambda x: torch.exp(torch.clamp(x, max=MAX_EXP))\n",
    "\n",
    "def cholesky_safe(mat, eps=1e-6):                          # mat (·, M, M)\n",
    "    eye = torch.eye(mat.size(-1), device=mat.device, dtype=mat.dtype)\n",
    "    try:\n",
    "        return torch.linalg.cholesky(mat + eps * eye)      # (·, M, M)\n",
    "    except RuntimeError:\n",
    "        eig_val, eig_vec = torch.linalg.eigh(mat)          # (·, M), (·, M, M)\n",
    "        eig_val = torch.clamp(eig_val, min=eps)\n",
    "        return eig_vec @ torch.diag_embed(torch.sqrt(eig_val))   # (·, M, M)\n",
    "\n",
    "# --------------------------- data -----------------------------------\n",
    "root = Path(\"oil_data\"); root.mkdir(exist_ok=True)\n",
    "url  = \"http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/resources/3PhData.tar.gz\"\n",
    "arc  = root / \"3PhData.tar.gz\"\n",
    "if not arc.exists():\n",
    "    urllib.request.urlretrieve(url, arc)\n",
    "with tarfile.open(arc) as tar:\n",
    "    tar.extract(\"DataTrn.txt\",     path=root)\n",
    "    tar.extract(\"DataTrnLbls.txt\", path=root)\n",
    "\n",
    "Y_np   = np.loadtxt(root / \"DataTrn.txt\")                  # (N, D)\n",
    "lbl_np = np.loadtxt(root / \"DataTrnLbls.txt\").astype(int)  # (N,)\n",
    "Y      = torch.tensor(Y_np,  device=DEV)                   # (N, D)\n",
    "lbl    = torch.tensor(lbl_np, device=DEV)                  # (N,)\n",
    "N, D   = Y.shape                                           # N=846, D=12\n",
    "Q = 2\n",
    "\n",
    "# ----------------------- latent variables ---------------------------\n",
    "mu_x    = torch.tensor(PCA(Q).fit_transform(Y_np),\n",
    "                       device=DEV, requires_grad=True)     # (N, Q)\n",
    "log_s2x = torch.full_like(mu_x, -2.0, requires_grad=True)  # (N, Q)\n",
    "\n",
    "# ------------------- kernel & inducing inputs -----------------------\n",
    "sqrtM = 8\n",
    "grid  = torch.linspace(-1.5, 1.5, sqrtM, device=DEV)       # (sqrtM,)\n",
    "Z     = torch.stack(torch.meshgrid(grid, grid, indexing=\"ij\"),\n",
    "                    -1).reshape(-1, Q)                     # (M=64, Q)\n",
    "M = Z.size(0)\n",
    "\n",
    "log_sf2      = torch.tensor(0.0,  device=DEV, requires_grad=True)  # ()\n",
    "log_alpha    = torch.zeros(Q,    device=DEV, requires_grad=True)   # (Q,)\n",
    "log_beta_inv = torch.tensor(-3.2, device=DEV, requires_grad=True)  # ()\n",
    "\n",
    "def k_se(x, z, log_sf2_val, log_alpha_val):\n",
    "    sf2   = safe_exp(log_sf2_val)                           # ()\n",
    "    alpha = safe_exp(log_alpha_val)                         # (Q,)\n",
    "    diff  = x.unsqueeze(-2) - z                             # (·, |x|, |z|, Q)\n",
    "    return sf2 * safe_exp(-0.5 * (diff ** 2 * alpha).sum(-1))  # (·, |x|, |z|)\n",
    "\n",
    "noise_var = lambda: safe_exp(log_beta_inv)                 # ()\n",
    "\n",
    "def update_K_and_inv():\n",
    "    Kmat = k_se(Z, Z,\n",
    "                log_sf2.clamp(*BOUNDS[\"log_sf2\"]),\n",
    "                log_alpha.clamp(*BOUNDS[\"log_alpha\"])) \\\n",
    "           + JITTER * torch.eye(M, device=DEV)             # (M, M)\n",
    "    L = cholesky_safe(Kmat)                                # (M, M)\n",
    "    return Kmat, torch.cholesky_inverse(L)                 # (M, M), (M, M)\n",
    "\n",
    "K_MM, K_inv = update_K_and_inv()                           # (M, M), (M, M)\n",
    "\n",
    "# ------------------------- q(U) block-diag --------------------------\n",
    "m_u = torch.zeros(D, M, device=DEV)                        # (D, M)\n",
    "C_u = torch.eye(M, device=DEV).expand(D, M, M).clone()     # (D, M, M)\n",
    "\n",
    "Sigma_u = lambda: C_u @ C_u.transpose(-1, -2)              # (D, M, M)\n",
    "\n",
    "def sample_U():\n",
    "    eps = torch.randn(D, M, device=DEV).unsqueeze(-1)      # (D, M, 1)\n",
    "    return m_u + (C_u @ eps).squeeze(-1)                   # (D, M)\n",
    "\n",
    "def natural_from_moment():\n",
    "    Lambda = -0.5 * torch.linalg.inv(Sigma_u())            # (D, M, M)\n",
    "    h = (-2.0 * Lambda @ m_u.unsqueeze(-1)).squeeze(-1)    # (D, M)\n",
    "    return h, Lambda\n",
    "\n",
    "def set_from_natural(h_new, Lambda_new, eps=1e-8):\n",
    "    global m_u, C_u\n",
    "    for d in range(D):\n",
    "        Lam_d = 0.5 * (Lambda_new[d] + Lambda_new[d].T)    # (M, M)\n",
    "        eig_val, eig_vec = torch.linalg.eigh(Lam_d)        # (M,), (M, M)\n",
    "        eig_val = torch.minimum(eig_val, -eps)\n",
    "        S_d = torch.linalg.inv((eig_vec * (-2.0 * eig_val)) @ eig_vec.T)  # (M, M)\n",
    "        C_u[d] = cholesky_safe(S_d, eps)                   # (M, M)\n",
    "        m_u[d] = S_d @ h_new[d]                            # (M,)\n",
    "\n",
    "Lambda_prior = (-0.5 * K_inv).expand(D, M, M).clone()      # (D, M, M)\n",
    "\n",
    "# --------------------- psi statistics -------------------------------\n",
    "def compute_psi(mu, s2):\n",
    "    \"\"\"\n",
    "    mu : (B, Q)\n",
    "    s2 : (B, Q)\n",
    "    Returns:\n",
    "        psi0 : (B,)\n",
    "        psi1 : (B, M)\n",
    "        psi2 : (B, M, M)\n",
    "    \"\"\"\n",
    "    sf2   = safe_exp(log_sf2.clamp(*BOUNDS[\"log_sf2\"]))    # ()\n",
    "    alpha = safe_exp(log_alpha.clamp(*BOUNDS[\"log_alpha\"]))# (Q,)\n",
    "\n",
    "    psi0 = torch.full((mu.size(0),), sf2.item(), device=DEV)  # (B,)\n",
    "\n",
    "    d1   = alpha * s2 + 1.0                              # (B, Q)\n",
    "    c1   = d1.rsqrt().prod(-1, keepdim=True)             # (B, 1)\n",
    "    diff = mu.unsqueeze(1) - Z                           # (B, M, Q)\n",
    "    psi1 = sf2 * c1 * safe_exp(-0.5 * ((alpha * diff ** 2) / d1.unsqueeze(1)).sum(-1))  # (B, M)\n",
    "\n",
    "    d2   = alpha * s2 + 2.0                              # (B, Q)\n",
    "    c2   = d2.rsqrt().prod(-1, keepdim=True)             # (B, 1)\n",
    "    ZZ   = Z.unsqueeze(1) - Z.unsqueeze(0)               # (M, M, Q)\n",
    "    dist = (alpha * ZZ ** 2).sum(-1)                     # (M, M)\n",
    "    mid  = 0.5 * (Z.unsqueeze(1) + Z.unsqueeze(0))       # (M, M, Q)\n",
    "    mu_c = (mu.unsqueeze(1).unsqueeze(1) - mid) ** 2     # (B, M, M, Q)\n",
    "    expo = -0.25 * dist - 0.5 * ((alpha * mu_c) / d2.unsqueeze(1).unsqueeze(1)).sum(-1)  # (B, M, M)\n",
    "    psi2 = sf2 ** 2 * c2.unsqueeze(-1).unsqueeze(-1) * safe_exp(expo)  # (B, M, M)\n",
    "\n",
    "    return psi0, psi1, psi2\n",
    "\n",
    "# --------------------------- local step ------------------------------\n",
    "def local_step(idx, U_sample, Sigma_det, update_beta, dbg=False):\n",
    "    \"\"\"\n",
    "    idx         : (B,)        mini-batch indices\n",
    "    U_sample    : (D, M)      sample of inducing outputs\n",
    "    Sigma_det   : (D, M, M)   detached covariance of q(U)\n",
    "    update_beta : bool        whether noise is trainable here\n",
    "    Returns     : scalar ELBO , r (B,D,M) , Q (B,D,M,M)\n",
    "    \"\"\"\n",
    "    mu = mu_x[idx]                          # (B, Q)\n",
    "    s2 = log_s2x[idx].exp()                 # (B, Q)\n",
    "    B  = mu.size(0)\n",
    "\n",
    "    psi0, psi1, psi2 = compute_psi(mu, s2)  # (B,), (B,M), (B,M,M)\n",
    "    A = psi1 @ K_inv                        # (B, M)\n",
    "\n",
    "    if dbg and DEBUG:\n",
    "        print(\"Shapes  A\", A.shape, \"psi1\", psi1.shape, \"psi2\", psi2.shape)\n",
    "\n",
    "    f_mean = A @ U_sample.T                 # (B, D)\n",
    "    var_f  = torch.stack([(A @ Sigma_det[d] * A).sum(-1) for d in range(D)], 1)  # (B, D)\n",
    "\n",
    "    noise = noise_var() if update_beta else noise_var().detach()  # ()\n",
    "    tr_term = (psi2 * K_inv).sum((-2, -1))            # (B,)\n",
    "    sigma2  = torch.clamp(noise + psi0 - tr_term, 1e-6, 1e3)  # (B,)\n",
    "    sigma2_unsq = sigma2.unsqueeze(-1)                # (B,1)\n",
    "\n",
    "    # ---------------- r ---------------------------------------------\n",
    "    Y_div = Y[idx] / sigma2_unsq                      # (B, D)\n",
    "    r = Y_div.unsqueeze(-1) * A.unsqueeze(1)          # (B, D, M)\n",
    "\n",
    "    # ---------------- Q ---------------------------------------------\n",
    "    A_exp  = A.unsqueeze(1)                           # (B, 1, M)\n",
    "    outer  = A_exp.transpose(-1, -2) * A_exp          # (B, 1, M, M)\n",
    "    outer  = outer.unsqueeze(1)                       # (B, 1, M, M)\n",
    "    outer  = outer.expand(B, D, M, M)                 # (B, D, M, M)\n",
    "    Q      = (-0.5 / sigma2_unsq).unsqueeze(-1).unsqueeze(-1) * outer  # (B, D, M, M)\n",
    "\n",
    "    quad   = ((Y[idx] - f_mean) ** 2 + var_f) / sigma2_unsq  # (B, D)\n",
    "    quad   = torch.clamp(quad, max=CLIP_QUAD)\n",
    "    log_like = (-0.5 * math.log(2.0 * math.pi)\n",
    "                - 0.5 * sigma2.log().unsqueeze(-1)\n",
    "                - 0.5 * quad).sum(-1)                 # (B,)\n",
    "    kl_x  = 0.5 * ((s2 + mu ** 2) - s2.log() - 1.0).sum(-1)  # (B,)\n",
    "\n",
    "    return (log_like - kl_x).mean(), r.detach(), Q.detach()   # scalar, (B,D,M), (B,D,M,M)\n",
    "\n",
    "# --------------------------- optimizers ------------------------------\n",
    "opt_x   = torch.optim.Adam([mu_x, log_s2x], lr=LR_X)\n",
    "opt_hyp = torch.optim.Adam([log_sf2, log_alpha, log_beta_inv], lr=LR_HYP)\n",
    "\n",
    "iters, elbo_hist = [], []\n",
    "for t in trange(1, T_TOTAL + 1, ncols=100):\n",
    "    Sigma_det = Sigma_u().detach()                       # (D, M, M)\n",
    "    idx       = torch.randint(0, N, (BATCH,), device=DEV)# (B,)\n",
    "\n",
    "    # ----- inner loop: update latent X ------------------------------\n",
    "    inner_iters = INNER0 if t <= 50 else INNER\n",
    "    for _ in range(inner_iters):\n",
    "        opt_x.zero_grad(set_to_none=True)\n",
    "        elbo_x, _, _ = local_step(idx, sample_U(),\n",
    "                                  Sigma_det, False, dbg=(t == 1))\n",
    "        (-elbo_x).backward(retain_graph=True)\n",
    "        torch.nn.utils.clip_grad_norm_([mu_x, log_s2x], GR_CLIP)\n",
    "        opt_x.step()\n",
    "        with torch.no_grad():\n",
    "            log_s2x.clamp_(*BOUNDS[\"log_s2x\"])\n",
    "\n",
    "    # ----- update kernel hyper-params and q(U) ----------------------\n",
    "    U_sample = sample_U()                                # (D, M)\n",
    "    elbo, r_b, Q_b = local_step(idx, U_sample, Sigma_u(), True)\n",
    "    opt_hyp.zero_grad(set_to_none=True)\n",
    "    (-elbo).backward()\n",
    "    opt_hyp.step()\n",
    "\n",
    "    # ----- natural-gradient step for q(U) --------------------------\n",
    "    with torch.no_grad():\n",
    "        for par, key in ((log_sf2, \"log_sf2\"),\n",
    "                         (log_alpha, \"log_alpha\"),\n",
    "                         (log_beta_inv, \"log_beta\")):\n",
    "            par.clamp_(*BOUNDS[key])\n",
    "\n",
    "        K_MM, K_inv = update_K_and_inv()                 # (M, M), (M, M)\n",
    "        Lambda_prior.copy_((-0.5 * K_inv).expand_as(Lambda_prior))  # (D, M, M)\n",
    "\n",
    "        h_nat, Lambda_nat = natural_from_moment()        # (D,M), (D,M,M)\n",
    "        r_sum, Q_sum = r_b.sum(0), Q_b.sum(0)            # (D,M), (D,M,M)\n",
    "        diff_U = (U_sample - m_u).unsqueeze(-1)          # (D, M, 1)\n",
    "        r_tilde = r_sum + 2.0 * (Q_sum @ diff_U).squeeze(-1)  # (D, M)\n",
    "\n",
    "        lr  = rho(t)\n",
    "        scale = N / idx.size(0)\n",
    "        h_new = (1.0 - lr) * h_nat + lr * scale * r_tilde               # (D, M)\n",
    "        Lambda_new = ((1.0 - lr) * Lambda_nat\n",
    "                      + lr * (Lambda_prior + scale * Q_sum))            # (D, M, M)\n",
    "        set_from_natural(h_new, Lambda_new)\n",
    "\n",
    "    # ----- monitoring ----------------------------------------------\n",
    "    if t % 25 == 0 or t == 1:\n",
    "        full_elbo, _, _ = local_step(torch.arange(N, device=DEV),\n",
    "                                     sample_U(), Sigma_u(), False)\n",
    "        iters.append(t); elbo_hist.append(full_elbo.item())\n",
    "        print(f\"\\nELBO @ {t:3d} : {full_elbo.item():.4e}\")\n",
    "\n",
    "# --------------------------- plots ----------------------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(iters, elbo_hist, \"-o\")\n",
    "plt.grid(ls=\":\")\n",
    "plt.xlabel(\"iteration\"); plt.ylabel(\"ELBO\"); plt.title(\"ELBO trajectory\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(mu_x.detach().cpu()[:, 0],\n",
    "            mu_x.detach().cpu()[:, 1],\n",
    "            c=lbl.cpu(), cmap=\"brg\", s=14)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"latent space\")\n",
    "plt.xlabel(\"mu_1\"); plt.ylabel(\"mu_2\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4838c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
