{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "657b44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A torch.Size([128, 64]) psi1 torch.Size([128, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (12) must match the size of tensor b (128) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_51916\\110931246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINNER0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mINNER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mopt_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0melbx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_U\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSigma_det\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdbg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0melbx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmu_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_s2x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGR_CLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mopt_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_51916\\110931246.py\u001b[0m in \u001b[0;36mlocal\u001b[1;34m(idx, U_s, Sigma_det, train_beta, dbg)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# ---------- r ----------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mYscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msigma2_unsq\u001b[0m                  \u001b[1;31m# (B,D)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mYscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# (B,D,M)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (12) must match the size of tensor b (128) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import math, tarfile, urllib.request, numpy as np, matplotlib.pyplot as plt, torch\n",
    "from pathlib import Path; from tqdm import trange; from sklearn.decomposition import PCA\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "DEV, DEBUG = (\"cuda\" if torch.cuda.is_available() else \"cpu\"), True\n",
    "LR_X, LR_HYP  = 5e-3, 1e-4\n",
    "BATCH, T_TOTAL, INNER0, INNER = 128, 100, 20, 5\n",
    "JITTER, MAX_EXP, CLIPQ, GR_CLIP = 1e-6, 60., 1e6, 10.\n",
    "BOUNDS = {\"log_sf2\": (-5., 6.), \"log_alpha\": (-5., 5.),\n",
    "          \"log_beta\": (-5., 2.), \"log_s2x\": (-5., 5.)}\n",
    "rho = lambda t, t0=200., k=.7: (t0+t)**(-k)\n",
    "safe_exp = lambda x: torch.exp(torch.clamp(x,max=MAX_EXP))\n",
    "def chol_or_eig(M,eps=1e-6):\n",
    "    I=torch.eye(M.size(-1),device=M.device,dtype=M.dtype)\n",
    "    try: return torch.linalg.cholesky(M+eps*I)\n",
    "    except RuntimeError:\n",
    "        e,v=torch.linalg.eigh(M); e=torch.clamp(e,min=eps)\n",
    "        return v@torch.diag(torch.sqrt(e))\n",
    "\n",
    "# ------------------------------ data --------------------------------\n",
    "root=Path(\"oil_data\"); root.mkdir(exist_ok=True)\n",
    "url =\"http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/resources/3PhData.tar.gz\"\n",
    "arc =root/\"3PhData.tar.gz\"\n",
    "if not arc.exists(): urllib.request.urlretrieve(url, arc)\n",
    "with tarfile.open(arc) as tar:\n",
    "    tar.extract(\"DataTrn.txt\",    path=root)\n",
    "    tar.extract(\"DataTrnLbls.txt\",path=root)\n",
    "Y_np = np.loadtxt(root/\"DataTrn.txt\")\n",
    "lbl_np=np.loadtxt(root/\"DataTrnLbls.txt\").astype(int)\n",
    "Y   = torch.tensor(Y_np,   device=DEV)\n",
    "lbl = torch.tensor(lbl_np, device=DEV)\n",
    "N,D = Y.shape;  Q=2\n",
    "\n",
    "# --------------------------- latent X -------------------------------\n",
    "mu_x    = torch.tensor(PCA(Q).fit_transform(Y_np), device=DEV, requires_grad=True)\n",
    "log_s2x = torch.full_like(mu_x,-2.0,requires_grad=True)\n",
    "\n",
    "# ---------------------- kernel & inducing ---------------------------\n",
    "sqrtM=8; grid=torch.linspace(-1.5,1.5,sqrtM,device=DEV)\n",
    "Z=torch.stack(torch.meshgrid(grid,grid,indexing=\"ij\"),-1).reshape(-1,Q); M=Z.size(0)\n",
    "log_sf2      = torch.tensor(0.,device=DEV,requires_grad=True)\n",
    "log_alpha    = torch.zeros(Q,device=DEV,requires_grad=True)\n",
    "log_beta_inv = torch.tensor(-3.2,device=DEV,requires_grad=True)\n",
    "\n",
    "def k_se(x,z,lsf,la):\n",
    "    sf2,a=safe_exp(lsf),safe_exp(la)\n",
    "    return sf2*safe_exp(-.5*((x[...,None,:]-z)**2*a).sum(-1))\n",
    "noise_var=lambda : safe_exp(log_beta_inv)\n",
    "\n",
    "def upd_Kinv():\n",
    "    K=k_se(Z,Z,\n",
    "           log_sf2.clamp(*BOUNDS[\"log_sf2\"]),\n",
    "           log_alpha.clamp(*BOUNDS[\"log_alpha\"])) \\\n",
    "      +JITTER*torch.eye(M,device=DEV)\n",
    "    L=chol_or_eig(K); return K,torch.cholesky_inverse(L)\n",
    "K_MM,Kinv=upd_Kinv()\n",
    "\n",
    "# ------------------------- q(U)  (block) ----------------------------\n",
    "m_u = torch.zeros(D,M,device=DEV)\n",
    "C_u = torch.eye(M,device=DEV).expand(D,M,M).clone()\n",
    "Sigma = lambda : C_u@C_u.transpose(-1,-2)\n",
    "sample_U = lambda : m_u + (C_u@torch.randn(D,M,device=DEV)[...,None]).squeeze(-1)\n",
    "\n",
    "def nat_from_mom():\n",
    "    Lam=-.5*torch.linalg.inv(Sigma()); h=(-2*Lam@m_u[...,None]).squeeze(-1)\n",
    "    return h,Lam\n",
    "def set_from_nat(h_new,Lam_new,eps=1e-8):\n",
    "    global m_u,C_u\n",
    "    for d in range(D):\n",
    "        Lam=.5*(Lam_new[d]+Lam_new[d].T)\n",
    "        eigv,eigvec=torch.linalg.eigh(Lam); eigv=torch.minimum(eigv,-eps)\n",
    "        Sd=torch.linalg.inv((eigvec*(-2*eigv))@eigvec.T)\n",
    "        C_u[d]=chol_or_eig(Sd,eps); m_u[d]=Sd@h_new[d]\n",
    "Lmb_prior=(-.5*Kinv).expand(D,M,M).clone()\n",
    "\n",
    "# ------------------------- psi-statistics ---------------------------\n",
    "def psi_stats(mu,s2):\n",
    "    sf2=safe_exp(log_sf2.clamp(*BOUNDS[\"log_sf2\"]))\n",
    "    a  =safe_exp(log_alpha.clamp(*BOUNDS[\"log_alpha\"]))\n",
    "    psi0=torch.full((mu.size(0),),sf2.item(),device=DEV)\n",
    "    d1=a*s2+1.; c1=d1.rsqrt().prod(-1,keepdim=True)\n",
    "    diff=mu[:,None,:]-Z; psi1=sf2*c1*safe_exp(-.5*((a*diff**2)/d1[:,None,:]).sum(-1))\n",
    "    d2=a*s2+2.; c2=d2.rsqrt().prod(-1,keepdim=True)\n",
    "    ZZ=Z[:,None,:]-Z[None,:,:]; dist=(a*ZZ**2).sum(-1)\n",
    "    mid=.5*(Z[:,None,:]+Z[None,:,:])\n",
    "    mc=(mu[:,None,None,:]-mid)**2\n",
    "    expo=-.25*dist -.5*((a*mc)/d2[:,None,None,:]).sum(-1)\n",
    "    psi2=sf2**2*c2[:,None,None]*safe_exp(expo)\n",
    "    return psi0,psi1,psi2\n",
    "\n",
    "# --------------------------- local ----------------------------------\n",
    "def local(idx,U_s,Sigma_det,train_beta,dbg=False):\n",
    "    mu,s2=mu_x[idx],log_s2x[idx].exp(); B=mu.size(0)\n",
    "    psi0,psi1,psi2=psi_stats(mu,s2)\n",
    "    A = psi1 @ Kinv                               # (B,M)\n",
    "\n",
    "    if dbg and DEBUG:\n",
    "        print(\"A\",A.shape,\"psi1\",psi1.shape)\n",
    "\n",
    "    fmu   = A @ U_s.T                             # (B,D)\n",
    "    var_f = torch.stack([(A@Sigma_det[d]*A).sum(-1) for d in range(D)],1)\n",
    "\n",
    "    base   = noise_var() if train_beta else noise_var().detach()\n",
    "    trace  = (psi2*Kinv).sum((-2,-1))             # (B,)\n",
    "    sigma2 = torch.clamp(base+psi0-trace,1e-6,1e3)# (B,)\n",
    "    sigma2_unsq = sigma2[:,None]                  # (B,1)\n",
    "\n",
    "    # ---------- r ----------------------------------------------------\n",
    "    Yscaled = Y[idx]/sigma2_unsq                  # (B,D)\n",
    "    r = (Yscaled[:,:,None]) * (A[:,None,:])       # (B,D,M)\n",
    "\n",
    "    # ---------- Q ----------------------------------------------------\n",
    "    Aexp   = A[:,None,:]                          # (B,1,M)\n",
    "    outer  = Aexp.transpose(-1,-2)*Aexp           # (B,1,M,M)\n",
    "    outer  = outer.expand(B,D,-1,-1)              # (B,D,M,M)\n",
    "    Q = (-.5/sigma2_unsq)[:,:,None,None]*outer    # (B,D,M,M)\n",
    "\n",
    "    quad=((Y[idx]-fmu)**2+var_f)/sigma2_unsq; quad=torch.clamp(quad,max=CLIPQ)\n",
    "    ll  = (-.5*math.log(2*math.pi)-.5*sigma2.log()[:,None] -.5*quad).sum(-1)\n",
    "    klx = .5*((s2+mu**2)-s2.log()-1.).sum(-1)\n",
    "    return (ll-klx).mean(), r.detach(), Q.detach()\n",
    "\n",
    "# --------------------------- optim ----------------------------------\n",
    "opt_x   = torch.optim.Adam([mu_x,log_s2x],lr=LR_X)\n",
    "opt_hyp = torch.optim.Adam([log_sf2,log_alpha,log_beta_inv],lr=LR_HYP)\n",
    "\n",
    "its,elbos=[],[]\n",
    "for t in trange(1,T_TOTAL+1,ncols=100):\n",
    "    Sigma_det=Sigma().detach(); idx=torch.randint(0,N,(BATCH,),device=DEV)\n",
    "\n",
    "    for _ in range(INNER0 if t<=50 else INNER):\n",
    "        opt_x.zero_grad(set_to_none=True)\n",
    "        elbx,_,_=local(idx,sample_U().detach(),Sigma_det,False,dbg=(t==1))\n",
    "        (-elbx).backward(retain_graph=True)\n",
    "        torch.nn.utils.clip_grad_norm_([mu_x,log_s2x],GR_CLIP); opt_x.step()\n",
    "        with torch.no_grad(): log_s2x.clamp_(*BOUNDS[\"log_s2x\"])\n",
    "\n",
    "    U_s=sample_U()\n",
    "    elbo,r_b,Q_b=local(idx,U_s,Sigma(),True)\n",
    "    opt_hyp.zero_grad(set_to_none=True); (-elbo).backward(); opt_hyp.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p,b in ((log_sf2,\"log_sf2\"),(log_alpha,\"log_alpha\"),(log_beta_inv,\"log_beta\")):\n",
    "            p.clamp_(*BOUNDS[b])\n",
    "        K_MM,Kinv=upd_Kinv(); Lmb_prior.copy_((-0.5*Kinv).expand_as(Lmb_prior))\n",
    "        h_nat,Lam_nat=nat_from_mom()\n",
    "        r_sum,Q_sum = r_b.sum(0),Q_b.sum(0)\n",
    "        r_tilde = r_sum + 2*(Q_sum @ (U_s-m_u)[...,None]).squeeze(-1)\n",
    "        lr,scale=rho(t),N/idx.size(0)\n",
    "        h_new =(1-lr)*h_nat  + lr*scale*r_tilde\n",
    "        Lam_new=(1-lr)*Lam_nat+ lr*(Lmb_prior+scale*Q_sum)\n",
    "        set_from_nat(h_new,Lam_new)\n",
    "\n",
    "    if t%25==0 or t==1:\n",
    "        full_elbo,_,_=local(torch.arange(N,device=DEV),sample_U(),Sigma(),False)\n",
    "        its.append(t); elbos.append(full_elbo.item())\n",
    "        print(f\"\\nELBO @ {t:3d}: {full_elbo.item():.4e}\")\n",
    "\n",
    "# --------------------------- plots ----------------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1); plt.plot(its,elbos,'-o'); plt.grid(ls=':')\n",
    "plt.xlabel('iteration'); plt.ylabel('ELBO'); plt.title('ELBO trajectory')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(mu_x.detach().cpu()[:,0],mu_x.detach().cpu()[:,1],\n",
    "            c=lbl.cpu(),cmap='brg',s=14)\n",
    "plt.gca().set_aspect('equal'); plt.title('latent space')\n",
    "plt.xlabel('mu_1'); plt.ylabel('mu_2'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4838c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
